{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a943f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f420c64d",
   "metadata": {},
   "source": [
    "# Предобработка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8672683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_features(events_data, submission_data):\n",
    "    \n",
    "    # построим таблицу со всеми действиями юзеров\n",
    "    users_events_data = pd.pivot_table(data=events_data, values='step_id',\n",
    "                                   index='user_id', columns='action',\n",
    "                                   aggfunc='count', fill_value=0) \\\n",
    "                                   .reset_index() \\\n",
    "                                   .rename_axis('', axis=1)\n",
    "    \n",
    "    # таблица с колво правильных и неправильных попыток\n",
    "    users_scores = pd.pivot_table(data=submission_data, \n",
    "                              values='step_id',\n",
    "                              index='user_id',\n",
    "                              columns='submission_status',\n",
    "                              aggfunc='count',\n",
    "                              fill_value=0).reset_index() \\\n",
    "                              .rename_axis('', axis=1)\n",
    "    \n",
    "    # соединяем в один датасет\n",
    "    users_data = pd.merge(users_scores, users_events_data, on='user_id', how='outer').fillna(0)\n",
    "    \n",
    "    assert users_data.user_id.nunique() == events_data.user_id.nunique()\n",
    "    \n",
    "    return users_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4655272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(events_data):\n",
    "    \n",
    "    # добавление колонок с датами\n",
    "    events_data['date'] = pd.to_datetime(events_data['timestamp'], unit='s')\n",
    "    events_data['day'] = events_data['date'].dt.date\n",
    "    \n",
    "    # создаем таблицу с первым\\последним действием юзера и колвом уникальных дней, проведенных на курсе\n",
    "    users_time_feature = events_data.groupby('user_id').agg({'timestamp': ['min', 'max'], 'day': 'nunique'}) \\\n",
    "                        .droplevel(level=0, axis=1) \\\n",
    "                        .rename(columns={'nunique': 'days'}) \\\n",
    "                        .reset_index()\n",
    "    \n",
    "    # добавление колонки с разницей между первым и последним появлением юзера,\n",
    "    # другими словами, сколько времени юзер потратил на прохождение в часах\n",
    "    users_time_feature['hours'] = round((users_time_feature['max'] - users_time_feature['min']) / 3600, 1)\n",
    "    \n",
    "    \n",
    "    return users_time_feature.drop(['max', 'min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e7f041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отфильтруем данные(Если не позднее двух дней с начала прохождения тестов)\n",
    "def time_filter(data, days=2):\n",
    "    \n",
    "    # создаем таблицу с первым и последним действием юзера\n",
    "    min_max_user_time = data.groupby('user_id').agg({'timestamp': 'min'}) \\\n",
    "                            .rename(columns={'timestamp': 'min_timestamp'}) \\\n",
    "                            .reset_index()\n",
    "    \n",
    "    data_time_filtered = pd.merge(data, min_max_user_time, on='user_id', how='outer')\n",
    "    \n",
    "    # отбираем те записи, которые не позднее двух дней с начала учебы\n",
    "    learning_time_threshold = days * 24 * 60 * 60\n",
    "    data_time_filtered = data_time_filtered.query(\"timestamp <= min_timestamp + @learning_time_threshold\")\n",
    "    \n",
    "    assert data_time_filtered.user_id.nunique() == data.user_id.nunique()\n",
    "    \n",
    "    return data_time_filtered.drop(['min_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c7b56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(submission_data, threshold=40):\n",
    "    \n",
    "    \"\"\"Вычисление целевой переменной. Если юзер сделал 40 практический заданий,\n",
    "    то будем считать, что он пройдет курс до конца\"\"\"\n",
    "    \n",
    "    # считаем колво решенных заданий у каждого пользователя\n",
    "    users_count_correct = submission_data[submission_data.submission_status == 'correct'] \\\n",
    "                .groupby('user_id').agg({'step_id': 'count'}) \\\n",
    "                .reset_index().rename(columns={'step_id': 'corrects'})\n",
    "    \n",
    "    # если юзер выполнил нужное колво заданий, то он пройдет курс до конца\n",
    "    users_count_correct['passed_course'] = (users_count_correct.corrects >= threshold).astype('int')\n",
    "    \n",
    "    return users_count_correct.drop(['corrects'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "daa1e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество уникальных степов, который пользователь решал\n",
    "def steps_tried(submission_data):\n",
    "    \n",
    "    \"\"\"Создание фичи с колвом уникальных шагов, которые пользователь пытался выполнить\"\"\"\n",
    "    \n",
    "    # сколько степов юзер попытался сделать\n",
    "    steps_tried = submission_data.groupby('user_id').step_id.nunique().to_frame().reset_index() \\\n",
    "                                        .rename(columns={'step_id': 'steps_tried'})\n",
    "    \n",
    "    return steps_tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1919b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доля правильных ответов пользователя\n",
    "def correct_ratio(data):\n",
    "\n",
    "    \"\"\"Создание фичи с долей правильных ответов\"\"\"\n",
    "    \n",
    "    data['correct_ratio'] = (data.correct / (data.correct + data.wrong)).fillna(0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0233506",
   "metadata": {},
   "source": [
    "# Создание датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "35ece7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "def create_df(events_data, submission_data):\n",
    "    \n",
    "    \"\"\"функция для формирования X датасета и y с целевыми переменными\"\"\"\n",
    "    \n",
    "    # фильтруем данные по дням от начала учебы\n",
    "    events_2days = time_filter(events_data)\n",
    "    submissions_2days = time_filter(submission_data)\n",
    "    \n",
    "    # создаем таблицу с базовыми фичами\n",
    "    users_data = base_features(events_2days, submissions_2days)\n",
    "    \n",
    "    # создаем целевую переменную\n",
    "    users_target_feature = target(submission_data, threshold=40)\n",
    "    \n",
    "    # создаем таблицу с временными фичами\n",
    "    users_time_feature = time_features(events_2days)\n",
    "    \n",
    "    # создаем фичи с попытками степов и долей правильных ответов\n",
    "    users_steps_tried = steps_tried(submissions_2days)\n",
    "    users_data = correct_ratio(users_data)\n",
    "    \n",
    "    # соединяем шаги\n",
    "    first_merge = users_data.merge(users_steps_tried, how='outer').fillna(0)\n",
    "    \n",
    "    # соединяем фичи со временем\n",
    "    second_merge = first_merge.merge(users_time_feature, how='outer')\n",
    "    \n",
    "    # присоединяем целевую переменную\n",
    "    third_merge = second_merge.merge(users_target_feature, how='outer').fillna(0)\n",
    "    \n",
    "    # отделяем целевую переменную и удаляем ее из основного датасета\n",
    "    y = third_merge['passed_course'].map(int)\n",
    "    X = third_merge.drop(['passed_course'], axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b33506b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "def create_test_df(events_data, submission_data):\n",
    "    \n",
    "    \"\"\"функция для формирования test датасета без целевой переменной\"\"\"\n",
    "    \n",
    "    # фильтруем данные по дням от начала учебы\n",
    "    events_2days = time_filter(events_data)\n",
    "    submissions_2days = time_filter(submission_data)\n",
    "    \n",
    "    # создаем таблицу с базовыми фичами\n",
    "    users_data = base_features(events_2days, submissions_2days)\n",
    "    \n",
    "    \n",
    "    # создаем таблицу с временными фичами\n",
    "    users_time_feature = time_features(events_2days)\n",
    "    \n",
    "    # создаем фичи с попытками степов и долей правильных ответов\n",
    "    users_steps_tried = steps_tried(submissions_2days)\n",
    "    users_data = correct_ratio(users_data)\n",
    "    \n",
    "    # соединяем шаги\n",
    "    first_merge = users_data.merge(users_steps_tried, how='outer').fillna(0)\n",
    "    \n",
    "    # соединяем фичи со временем\n",
    "    X = first_merge.merge(users_time_feature, how='outer')\n",
    "       \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d1784e",
   "metadata": {},
   "source": [
    "# Загрузка датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "712bb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "events_data_train = pd.read_csv('https://stepik.org/media/attachments/course/4852/event_data_train.zip')\n",
    "submission_data_train = pd.read_csv('https://stepik.org/media/attachments/course/4852/submissions_data_train.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "541c251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "events_data_test = pd.read_csv('https://stepik.org/media/attachments/course/4852/events_data_test.csv')\n",
    "submission_data_test = pd.read_csv('https://stepik.org/media/attachments/course/4852/submission_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b126e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train, y = create_df(events_data_train, submission_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c014cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = create_test_df(events_data_test, submission_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8abea6",
   "metadata": {},
   "source": [
    "# Обучение модели RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3d09a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fba7ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск лучший параметров\n",
    "def random_with_grid(train_data, y, size=0.20):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=size, random_state=42)\n",
    "    \n",
    "    param_grid = {'randomforestclassifier__n_estimators': range(10, 50), \n",
    "                  'randomforestclassifier__max_depth': range(3, 15)}\n",
    "    \n",
    "    pipe = make_pipeline(RandomForestClassifier())\n",
    "    pipe.fit(X_train, y_train)\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Наилучшие параметры: {grid.best_params_}\")\n",
    "    \n",
    "    ypred_prob = grid.predict_proba(X_test)\n",
    "    \n",
    "    roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
    "    score = grid.score(X_test, y_test)\n",
    "    print(f\"Правильность на тестовом наборе: {score:.2f}\")\n",
    "    print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "70858839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_final(train_data, y, test_data, size=0.20):\n",
    "    \n",
    "    test_data = test_data.sort_values('user_id')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=size, random_state=42)\n",
    "    \n",
    "    pipe = make_pipeline(RandomForestClassifier(max_depth=7, n_estimators=40,  random_state=42))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    ypred_prob = pipe.predict_proba(X_test)\n",
    "    \n",
    "    roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
    "    score = pipe.score(X_test, y_test)\n",
    "    print(f\"Правильность на валид наборе: {score:.3f}\")\n",
    "    print(f\"Roc_auc_score на валид наборе: {roc_score:.5f}\")\n",
    "    \n",
    "    ypred_prob_final = pipe.predict_proba(test_data)\n",
    "    result = test_data['user_id'].to_frame()\n",
    "    result['is_gone'] = ypred_prob_final[:, 1]\n",
    "    result[['user_id', 'is_gone']].to_csv(f'my_predict_{roc_score:.5f}.csv', index=False)\n",
    "    print(f'Результы записанны в файл my_predict_{roc_score:.5f}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "55727c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на валид наборе: 0.903\n",
      "Roc_auc_score на валид наборе: 0.88603\n",
      "Результы записанны в файл my_predict_0.88603.csv\n"
     ]
    }
   ],
   "source": [
    "random_final(X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e86a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
